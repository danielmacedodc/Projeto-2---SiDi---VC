{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9533c8ce",
   "metadata": {},
   "source": [
    "# Modelos de Classificação - Hepatite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "976d1b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas de manipualção e visualização de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "# Classes dos modelo\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from mord import LogisticAT\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Essemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Funções de avaliação dos modelos\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score, plot_confusion_matrix, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "#SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#PerC\n",
    "from PerC.src.data.build_dataset import build, normalize\n",
    "from PerC.src.model.classification.perturbation import PerC_Mean, PerC_Covariance, PerC\n",
    "\n",
    "# Seleção de Features e redução de dimencionalidade\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f1144b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset sem outliers\n",
    "df_hepatite = pd.read_csv('HCV-Egy-Data-no-outlier.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c76e488",
   "metadata": {},
   "source": [
    "A remoção de outliers mostrou-se eficiente na performace do modelo aumentando em serca de 1% a acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8cb0768c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Nausea/Vomting</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Diarrhea</th>\n",
       "      <th>FGba</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>...</th>\n",
       "      <th>ALT 24</th>\n",
       "      <th>ALT 36</th>\n",
       "      <th>ALT 48</th>\n",
       "      <th>ALT after 24 w</th>\n",
       "      <th>RNA Base</th>\n",
       "      <th>RNA 4</th>\n",
       "      <th>RNA 12</th>\n",
       "      <th>RNA EOT</th>\n",
       "      <th>RNA EF</th>\n",
       "      <th>Baselinehistological staging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>113</td>\n",
       "      <td>57</td>\n",
       "      <td>123</td>\n",
       "      <td>44</td>\n",
       "      <td>40620</td>\n",
       "      <td>538635</td>\n",
       "      <td>637056</td>\n",
       "      <td>336804</td>\n",
       "      <td>31085</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>48</td>\n",
       "      <td>77</td>\n",
       "      <td>33</td>\n",
       "      <td>1041941</td>\n",
       "      <td>449939</td>\n",
       "      <td>585688</td>\n",
       "      <td>744463</td>\n",
       "      <td>582301</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>114</td>\n",
       "      <td>29</td>\n",
       "      <td>1157452</td>\n",
       "      <td>1086852</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>84</td>\n",
       "      <td>80</td>\n",
       "      <td>28</td>\n",
       "      <td>325694</td>\n",
       "      <td>1034008</td>\n",
       "      <td>275095</td>\n",
       "      <td>214566</td>\n",
       "      <td>635157</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>96</td>\n",
       "      <td>53</td>\n",
       "      <td>39</td>\n",
       "      <td>641129</td>\n",
       "      <td>72050</td>\n",
       "      <td>787295</td>\n",
       "      <td>370605</td>\n",
       "      <td>506296</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Age  Gender  BMI  Fever  Nausea/Vomting  Headache  Diarrhea  \\\n",
       "0           1   46       1   29      1               2         2         1   \n",
       "1           3   49       2   33      1               2         1         2   \n",
       "2           5   58       2   22      2               2         2         1   \n",
       "3           6   42       2   26      1               1         2         2   \n",
       "4           7   48       2   30      1               1         2         2   \n",
       "\n",
       "   FGba  Jaundice  ...  ALT 24  ALT 36  ALT 48  ALT after 24 w  RNA Base  \\\n",
       "0     2         2  ...     113      57     123              44     40620   \n",
       "1     1         2  ...      88      48      77              33   1041941   \n",
       "2     2         2  ...      65      73     114              29   1157452   \n",
       "3     2         2  ...     107      84      80              28    325694   \n",
       "4     1         1  ...      45      96      53              39    641129   \n",
       "\n",
       "     RNA 4  RNA 12  RNA EOT  RNA EF  Baselinehistological staging  \n",
       "0   538635  637056   336804   31085                             2  \n",
       "1   449939  585688   744463  582301                             3  \n",
       "2  1086852       5        5       5                             4  \n",
       "3  1034008  275095   214566  635157                             4  \n",
       "4    72050  787295   370605  506296                             3  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hepatite.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31fde9e",
   "metadata": {},
   "source": [
    "Ao exportar o dataset sem outliers surgiu a coluna `Unnamed: 0` que será removida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dc3afbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hepatite.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f78bc7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1381 entries, 0 to 1380\n",
      "Data columns (total 28 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Age                           1381 non-null   int64  \n",
      " 1   Gender                        1381 non-null   int64  \n",
      " 2   BMI                           1381 non-null   int64  \n",
      " 3   Fever                         1381 non-null   int64  \n",
      " 4   Nausea/Vomting                1381 non-null   int64  \n",
      " 5   Headache                      1381 non-null   int64  \n",
      " 6   Diarrhea                      1381 non-null   int64  \n",
      " 7   FGba                          1381 non-null   int64  \n",
      " 8   Jaundice                      1381 non-null   int64  \n",
      " 9   Ep                            1381 non-null   int64  \n",
      " 10  WBC                           1381 non-null   int64  \n",
      " 11  RBC                           1381 non-null   float64\n",
      " 12  HGB                           1381 non-null   int64  \n",
      " 13  Plat                          1381 non-null   float64\n",
      " 14  AST 1                         1381 non-null   int64  \n",
      " 15  ALT 1                         1381 non-null   int64  \n",
      " 16  ALT4                          1381 non-null   float64\n",
      " 17  ALT 12                        1381 non-null   int64  \n",
      " 18  ALT 24                        1381 non-null   int64  \n",
      " 19  ALT 36                        1381 non-null   int64  \n",
      " 20  ALT 48                        1381 non-null   int64  \n",
      " 21  ALT after 24 w                1381 non-null   int64  \n",
      " 22  RNA Base                      1381 non-null   int64  \n",
      " 23  RNA 4                         1381 non-null   int64  \n",
      " 24  RNA 12                        1381 non-null   int64  \n",
      " 25  RNA EOT                       1381 non-null   int64  \n",
      " 26  RNA EF                        1381 non-null   int64  \n",
      " 27  Baselinehistological staging  1381 non-null   int64  \n",
      "dtypes: float64(3), int64(25)\n",
      "memory usage: 302.2 KB\n"
     ]
    }
   ],
   "source": [
    "df_hepatite.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de74a3af",
   "metadata": {},
   "source": [
    "### Seperação da váriável target do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "345b733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_hepatite.drop('Baselinehistological staging', axis=1)\n",
    "y = df_hepatite['Baselinehistological staging']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f313c122",
   "metadata": {},
   "source": [
    "## Pipeline dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e7e715f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9300e0f8",
   "metadata": {},
   "source": [
    "**Pipeline com dados númericos**\n",
    "\n",
    "Com a normalização dos dados o modelo de predição almentou em um valor de 6% sua acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3f7c2978",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_numerico = Pipeline([\n",
    "    ('std_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0eba7733",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = X.drop(['Gender', 'Fever', 'Nausea/Vomting', 'Headache', 'Diarrhea', 'FGba', 'Jaundice', 'Ep'], axis=1)\n",
    "X_num_tr = pipeline_numerico.fit_transform(X_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23e08ed",
   "metadata": {},
   "source": [
    "**Pipeline com dados categóricos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "08bbaf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num_std = pipeline_numerico.fit_transform(X_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3643b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.preprocessing import OrdinalEncoder # just to raise an ImportError if Scikit-Learn < 0.20\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "except ImportError:\n",
    "    from future_encoders import OneHotEncoder # Scikit-Learn < 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3e590ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "except ImportError:\n",
    "    from future_encoders import ColumnTransformer # Scikit-Learn < 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a33b55d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista com os atributos categóricos\n",
    "atributos_cat = ['Gender', 'Fever', 'Nausea/Vomting', 'Headache', 'Diarrhea', 'FGba', 'Jaundice', 'Ep']\n",
    "# lista com os atributos númericos\n",
    "atributos_num = list(X.drop(['Gender', 'Fever', 'Nausea/Vomting', 'Headache', 'Diarrhea', 'FGba', 'Jaundice', 'Ep'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "99aed4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_num_cat = ColumnTransformer([\n",
    "    ('num', pipeline_numerico, atributos_num),\n",
    "    ('cat', OneHotEncoder(), atributos_cat)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "963232c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = pipeline_num_cat.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326547bd",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "06bc361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = {1:1500, 2:1500, 3:1500, 4:1500}\n",
    "oversample = SMOTE(sampling_strategy=strategy)\n",
    "X_final, y = oversample.fit_resample(X_final, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2c2e8f",
   "metadata": {},
   "source": [
    "## Funções para executar os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b86d6693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que retorna um dicionário com os valores dos resultados\n",
    "def model_results(model, X_train, y_train, X_test, y_test,results_dict_aux):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # medindo e armazenando acurácia e f1-scoreno dicionário\n",
    "    # accuracy = model.score(X_test, y_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    # AUC = roc_auc_score(y_test, model.predict_proba(X_test), average='weighted', multi_class='ovo')\n",
    "    CM = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    results_dict_aux['accuracy'].append(accuracy)\n",
    "    results_dict_aux['f1'].append(f1)\n",
    "    #results_dict_aux['auc'].append(AUC)\n",
    "    results_dict_aux['cm'].append(CM)\n",
    "    \n",
    "    #print(f\"f1: %.6f\\n\" %(f1))\n",
    "    #print(f\"Accuracy: %.6f\\n\" %(accuracy))\n",
    "    #print(f\"AUC: %.6f\" %(AUC))\n",
    "    #print(f\"CM: \\n{CM} \\n\")\n",
    "    '''\n",
    "    print(\"-----------------------CURVA ROC---------------------\")\n",
    "    visualizer = ROCAUC(model, encoder={1:\"Class 1\", 2:\"Class 2\", 3:\"Class 3\", 4:\"Class 4\"})\n",
    "\n",
    "    visualizer.fit(X_train, y_train)        \n",
    "    visualizer.score(X_test, y_test)        \n",
    "    visualizer.show()                       \n",
    "    #print(\"-----------------------------------------------------\\n\")'''\n",
    "    \n",
    "    return results_dict_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1fa7c0",
   "metadata": {},
   "source": [
    "## RandomizedSearch\n",
    "\n",
    "Para cada modelo é implementada uma função do RandomizedSearch. Para ser aplicada em cada um dos 10 conjuntos de treino do 10-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1a4ebd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_search(model, param_grid, X, y):\n",
    "\n",
    "    # defining parameter range\n",
    "    grid = RandomizedSearchCV(model, param_grid, cv=3,random_state=199, scoring='accuracy', n_jobs=5)\n",
    "    # fitting the model for grid search\n",
    "    grid.fit(X, y)\n",
    "    #utilizando melhores parâmetros calculados pelo gridsearch\n",
    "    dic_best = grid.best_params_\n",
    "    \n",
    "    return dic_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd15fef",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2727b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicionário com parêmetros para o gridsearch\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [impar for impar in range(1,32) if (impar%2)!=0],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidian','manhattan','chebyshev']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db3ba7",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "89a5bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicionário com parêmetros para o gridsearch\n",
    "dt_param_grid = {\n",
    "    'max_depth': [x for x in range(1,32)],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fce1a4",
   "metadata": {},
   "source": [
    "**MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cfe9d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicionário com parêmetros para o gridsearch\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (50, 15, 5), (100, 25, 10)],\n",
    "    'activation': ['tanh', 'relu', 'logistic'],\n",
    "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'learning_rate_init': [0.1, 0.01, 0.001],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db79b59",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0306a680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicionário com parêmetros para o gridsearch\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['rbf','sigmoid', 'linear'], #['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    'gamma': [1, 0.1, 0.01, 0.001]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7e82a4",
   "metadata": {},
   "source": [
    "**Regressão Logística Multimodal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "897d5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_param_grid = {\n",
    "    'penalty': ['l2', 'none'],\n",
    "    'solver': ['newton-cg', 'sag', 'lbfgs']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ffbd07",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "38edae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# profundidade máxima\n",
    "max_depth = [int(x) for x in np.linspace(100, 300, num = 11)]\n",
    "max_depth.append(None)\n",
    "# grid\n",
    "rf_param_grid = {\n",
    " 'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 500, num = 10)],\n",
    " 'max_depth': max_depth,\n",
    " # numero de features a serem consideradas em cada fold\n",
    " 'max_features': ['auto', 'sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75482419",
   "metadata": {},
   "source": [
    "**Gradiente Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "eb47581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_param_grid = {\n",
    "    \"loss\":[\"deviance\", \"exponential\"],\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[10]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee7fd4f",
   "metadata": {},
   "source": [
    "**Extreme Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0306cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\n",
    "    \"objective\": ['multi:softmax'],\n",
    "    \"max_depth\": range (2, 10, 1),\n",
    "    \"n_estimators\": range(60, 220, 40),\n",
    "    \"learning_rate\": [0.1, 0.01, 0.05],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48feb7d2",
   "metadata": {},
   "source": [
    "**Ada Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a540b93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_param_grid = {\n",
    "    'n_estimators':[int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)],\n",
    "    'learning_rate':[.001,0.01, 0.1, 1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced7f3c",
   "metadata": {},
   "source": [
    "## Hold-out\n",
    "\n",
    "Antes de realizar o 10-Fold os dados serão separados em treino e teste através do método **hold-out**. O data set de treino será utilizado para validar os modelos e escolher os melhores parâmetros com o **10-fold** para então comparar o modelos com o data set de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "09a37e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.3, random_state=199, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3ab1c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converte para numpy array\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6c3650",
   "metadata": {},
   "source": [
    "## 10-Fold\n",
    "\n",
    "Com esse método são criados 10 datasets de treino e 10 datasets de test com uma divisão de 90% para treino e 10% para teste em cada divisão.\n",
    "\n",
    "O conjunto de treino sera divido mais uma vez em treino e validação (isso é feito dendo da função `GridSearchCV` para que então seja aplicado o GridSearch e assim obtenha-se os melhores parâmetros. Por fim, tendo os melhores parâmetros, utiliza-se o conjunto de teste para que se possa avaliar os resultados.\n",
    "\n",
    "Esses resultados são obtidos de cada fold e então se tira a média deles para obter-se a avaliação final de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "32bbbb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_restults(results_dict_models):    \n",
    "    # a cada interação calcula a média e o desvio padrão da \n",
    "    # acurácia, f1-score e matriz de confusão de cada modelo\n",
    "    for model_key in results_dict_models.keys():\n",
    "        accuracies = np.array(results_dict_models[model_key]['accuracy'])\n",
    "        f1 = np.array(results_dict_models[model_key]['f1'])\n",
    "        #auc = np.array(results_dict_models[model_key]['auc'])\n",
    "        conf_matrix = np.array(results_dict_models[model_key]['cm'])\n",
    "\n",
    "        print_mean_result(model_key, accuracies, f1, conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6f954d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_best_results(best_dict_knn, best_dict_dt, best_dict_mlp, best_dict_svm, best_dict_mlr, best_dict_rf, best_dict_xgb, best_dict_gb , best_dict_ab):\n",
    "    print(\"\\n------- BEST PARAMETERS -------\")\n",
    "    print(f\"KNN: {best_dict_knn}\")\n",
    "    print(f\"DT: {best_dict_dt}\")\n",
    "    print(f\"MLP: {best_dict_mlp}\")\n",
    "    print(f\"SVM: {best_dict_svm}\")\n",
    "    print(f\"MLR: {best_dict_mlr}\")\n",
    "    print(f\"RF: {best_dict_rf}\") \n",
    "    print(f\"XGB: dic:{best_dict_xgb}\") \n",
    "    print(f\"GB: dic:{best_dict_gb}\") \n",
    "    print(f\"AB: dic:{best_dict_ab}\")\n",
    "    print(\"--------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2566fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mean_result(model_key, accuracies, f1, conf_matrix):\n",
    "    print(f\"\\t{model_key}\")\n",
    "    print(\"Acurácia média (desvio): %.6f +- (%.6f)\" %(accuracies.mean(), accuracies.std()))\n",
    "    print(\"F1-score média (desvio): %.6f +- (%.6f)\" %(f1.mean(), f1.std()))\n",
    "    #print(\"AUC média (desvio): %.6f +- (%.6f)\\n\" %(auc.mean(), auc.std()))\n",
    "    print(f\"Matriz de Confusão:  \\n{sum(conf_matrix)*0.1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ac1b239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que roda os modelos em cada uma das divisões do 10-fold\n",
    "#e imprime a média e o desvio padrão dos resultados\n",
    "\n",
    "def evaluate_model_with_kfold(kf):\n",
    "    results_dict_models = {}\n",
    "    # listas e dicionarios para salvar as métricas dos resultados de todas as interacoes\n",
    "    # a key 'best'salva a melhor acurácia\n",
    "    \n",
    "    results_dict_KNN = {\n",
    "        'accuracy': [],\n",
    "        'f1': [],\n",
    "        #'auc': [],\n",
    "        'cm': [],\n",
    "        'best': 0.0\n",
    "    }\n",
    "    \n",
    "    results_dict_PERC = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_DT = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_MLP = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_SVM = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_GNB = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_MLR = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_RF = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_XGB = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_GB = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_AB = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "\n",
    "    \n",
    "    # váriável para salvar os melhores parâmetros\n",
    "    best_dict_knn, best_dict_dt, best_dict_mlp, best_dict_svm, best_dict_mlr, best_dict_rf, best_dict_xgb, best_dict_gb , best_dict_ab = {}, {}, {}, {}, {}, {}, {}, {}, {}\n",
    "    \n",
    "    fold = 0\n",
    "    \n",
    "    # laço que roda todos os modelos em cada 1-fold\n",
    "    for train, test in kf.split(X_train, y_train):\n",
    "        \n",
    "        # usa a lista retornada pelo .split para selicionar as intâncias de cada fold\n",
    "        X_train_kf = X_train[train,:] \n",
    "        y_train_kf = y_train[train]\n",
    "        X_test_kf = X_train[test,:]\n",
    "        y_test_kf = y_train[test]\n",
    "        \n",
    "        # para acompanhar a execução \n",
    "        fold += 1\n",
    "        print(f\"\\n{fold}º fold\")\n",
    "        \n",
    "        # Método de seleção de features não supervisionado\n",
    "        # Limiar de variância - retira-se as features com variância menor que 85%\n",
    "        filter_variance = VarianceThreshold(0.85)\n",
    "        filter_variance.fit(X_train_kf)\n",
    "        X_train_kf = filter_variance.transform(X_train_kf)\n",
    "        X_test_kf = filter_variance.transform(X_test_kf)\n",
    "        print(\"Features selecionadas: %d\" %(X_train_kf.shape[1]))\n",
    "        \n",
    "        #kNN\n",
    "        print(\"-KNN\")\n",
    "        dict_knn = Random_search(knn(), knn_param_grid, X_train_kf, y_train_kf)\n",
    "        model = knn(**dict_knn)\n",
    "        results_dict_KNN = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_KNN)\n",
    "        #verifica se os parêmetros do fold atual são os melhores\n",
    "        if (results_dict_KNN['accuracy'][-1] > results_dict_KNN['best']): \n",
    "            results_dict_KNN['best'] = results_dict_KNN['accuracy'][-1]\n",
    "            best_dict_knn = dict_knn \n",
    "            \n",
    "        #PerC\n",
    "        print(\"-PerC\")\n",
    "        model = PerC()\n",
    "        results_dict_PERC = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_PERC)\n",
    "            \n",
    "        #DT\n",
    "        print(\"-DT\")\n",
    "        dict_dt = Random_search(DecisionTreeClassifier(), dt_param_grid, X_train_kf, y_train_kf)\n",
    "        model = DecisionTreeClassifier(**dict_dt, random_state=199)\n",
    "        results_dict_DT = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_DT)\n",
    "        #verifica se os parêmetros do fold atual são os melhores\n",
    "        if (results_dict_DT['accuracy'][-1] > results_dict_DT['best']): \n",
    "            results_dict_DT['best'] = results_dict_DT['accuracy'][-1]\n",
    "            best_dict_dt = dict_dt\n",
    "        \n",
    "        \n",
    "        #MLP \n",
    "        print(\"-MLP\")\n",
    "        dict_mlp = Random_search(MLPClassifier(),mlp_param_grid, X_train_kf,y_train_kf)\n",
    "        model = MLPClassifier(**dict_mlp, max_iter=2000, tol=0.000001, random_state=199)\n",
    "        results_dict_MLP = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_MLP)\n",
    "        #verifica se os parêmetros do fold atual são os melhores comparando a acurácia\n",
    "        if (results_dict_MLP['accuracy'][-1] > results_dict_MLP['best']): \n",
    "            results_dict_MLP['best'] = results_dict_MLP['accuracy'][-1]\n",
    "            best_dict_mlp = dict_mlp\n",
    "        \n",
    "        #GNB \n",
    "        print(\"-GNB\")\n",
    "        model = GaussianNB()\n",
    "        results_dict_models['GNB'] = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_GNB)\n",
    "        \n",
    "        #SVM\n",
    "        print(\"-SVM\")\n",
    "        dict_svm = Random_search(SVC(), svm_param_grid, X_train_kf, y_train_kf)\n",
    "        model = SVC(**dict_svm, probability=True, random_state=199)\n",
    "        results_dict_SVM = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_SVM)\n",
    "        #verifica se os parêmetros do fold atual são os melhores\n",
    "        if (results_dict_SVM['accuracy'][-1] > results_dict_SVM['best']): \n",
    "            results_dict_SVM['best'] = results_dict_SVM['accuracy'][-1]\n",
    "            best_dict_svm = dict_svm           \n",
    "        \n",
    "        # Regressão Logística Multimodal\n",
    "        print(\"-MLR\")\n",
    "        dict_mlr = Random_search(LogisticRegression(), mlr_param_grid, X_train_kf, y_train_kf)\n",
    "        model = LogisticRegression(**dict_mlr, multi_class='multinomial', random_state=199)\n",
    "        results_dict_MLR = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_MLR)\n",
    "        #verifica se os parêmetros do fold atual são os melhores\n",
    "        if (results_dict_MLR['accuracy'][-1] > results_dict_MLR['best']): \n",
    "            results_dict_MLR['best'] = results_dict_MLR['accuracy'][-1]\n",
    "            best_dict_mlr = dict_mlr \n",
    "        \n",
    "        # Random Forest\n",
    "        print(\"-RF\")\n",
    "        dict_rf = Random_search(RandomForestClassifier(), rf_param_grid, X_train_kf, y_train_kf)\n",
    "        model = RandomForestClassifier(**dict_rf, random_state=199)\n",
    "        results_dict_RF = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_RF)\n",
    "        #verifica se os parêmetros do fold atual são os melhores\n",
    "        if (results_dict_RF['accuracy'][-1] > results_dict_RF['best']): \n",
    "            results_dict_RF['best'] = results_dict_RF['accuracy'][-1]\n",
    "            best_dict_rf = dict_rf \n",
    "      \n",
    "        # Ada Boosting\n",
    "        print(\"-AB\")\n",
    "        dict_ab = Random_search(AdaBoostClassifier(), ab_param_grid, X_train_kf, y_train_kf)\n",
    "        model = AdaBoostClassifier(**dict_ab, random_state=199)\n",
    "        results_dict_AB = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_AB)\n",
    "        #verifica se os parêmetros do fold atual são os melhores\n",
    "        if (results_dict_AB['accuracy'][-1] > results_dict_AB['best']): \n",
    "            results_dict_AB['best'] = results_dict_AB['accuracy'][-1]\n",
    "            best_dict_ab = dict_ab\n",
    "      \n",
    "        # EXtrem Gradiente Boosting\n",
    "        print(\"-XGB\")\n",
    "        dict_xgb = Random_search(XGBClassifier(), xgb_param_grid, X_train_kf, y_train_kf)\n",
    "        model = XGBClassifier(**dict_xgb, random_state=199)\n",
    "        results_dict_XGB = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_XGB)\n",
    "        #verifica se os parêmetros do fold atual são os melhores\n",
    "        if (results_dict_XGB['accuracy'][-1] > results_dict_XGB['best']): \n",
    "            results_dict_XGB['best'] = results_dict_XGB['accuracy'][-1]\n",
    "            best_dict_xgb = dict_xgb\n",
    "      \n",
    "        # GB\n",
    "        print(\"-GB\")\n",
    "        dict_gb = Random_search(GradientBoostingClassifier(), gb_param_grid, X_train_kf, y_train_kf)\n",
    "        model = GradientBoostingClassifier(**dict_gb, random_state=199)\n",
    "        results_dict_GB = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_GB)\n",
    "        #verifica se os parêmetros do fold atual são os melhores\n",
    "        if (results_dict_GB['accuracy'][-1] > results_dict_GB['best']): \n",
    "            results_dict_GB['best'] = results_dict_GB['accuracy'][-1]\n",
    "            best_dict_gb = dict_gb        \n",
    "        \n",
    "    results_dict_models['KNN'] = results_dict_KNN\n",
    "    results_dict_models['DT'] = results_dict_DT\n",
    "    results_dict_models['MLP'] = results_dict_MLP\n",
    "    results_dict_models['GNB'] = results_dict_GNB\n",
    "    results_dict_models['SVM'] = results_dict_SVM\n",
    "    results_dict_models['MLR'] = results_dict_MLR\n",
    "    results_dict_models['RF'] = results_dict_RF\n",
    "    results_dict_models['XGB'] = results_dict_XGB\n",
    "    results_dict_models['GB'] = results_dict_GB\n",
    "    results_dict_models['AB'] = results_dict_AB\n",
    "    \n",
    "    # calcula a média dos resultados e imprime cada métrica\n",
    "    calculate_mean_restults(results_dict_models)\n",
    "\n",
    "    # imprime os melhores parâmetros\n",
    "    print_best_results(best_dict_knn, best_dict_dt, best_dict_mlp, best_dict_svm, best_dict_mlr, best_dict_rf, best_dict_xgb, best_dict_ab, best_dict_gb)\n",
    "    \n",
    "    # salva os melhores parâmetros em um dicionário que é o retorno da função\n",
    "    parameters_dict = {\n",
    "        'knn': best_dict_knn,\n",
    "        'dt': best_dict_dt,\n",
    "        'mlp': best_dict_mlp,\n",
    "        'svm': best_dict_svm,\n",
    "        'mlr': best_dict_mlr,\n",
    "        'rf': best_dict_rf,\n",
    "        'xgb': best_dict_xgb,\n",
    "        'gb': best_dict_gb,\n",
    "        'ab': best_dict_ab\n",
    "    }\n",
    "    \n",
    "    return parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7a49a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c1d9f383",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1º fold\n",
      "Features selecionadas: 4\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[23:00:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:00:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "2º fold\n",
      "Features selecionadas: 4\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[23:02:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:02:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "3º fold\n",
      "Features selecionadas: 4\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[23:04:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:04:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "4º fold\n",
      "Features selecionadas: 5\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[23:07:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "5º fold\n",
      "Features selecionadas: 5\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[23:09:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "6º fold\n",
      "Features selecionadas: 5\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[23:10:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "7º fold\n",
      "Features selecionadas: 4\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[23:12:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:12:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "8º fold\n",
      "Features selecionadas: 5\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[23:13:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:13:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "9º fold\n",
      "Features selecionadas: 4\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[23:15:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "10º fold\n",
      "Features selecionadas: 4\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[23:16:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\tGNB\n",
      "Acurácia média (desvio): 0.285476 +- (0.022397)\n",
      "F1-score média (desvio): 0.272933 +- (0.021815)\n",
      "Matriz de Confusão:  \n",
      "[[14.1 42.  25.5 23.4]\n",
      " [12.3 48.6 17.4 26.7]\n",
      " [11.3 40.3 27.8 25.6]\n",
      " [11.6 40.5 23.5 29.4]]\n",
      "\tKNN\n",
      "Acurácia média (desvio): 0.549762 +- (0.061274)\n",
      "F1-score média (desvio): 0.549312 +- (0.061510)\n",
      "Matriz de Confusão:  \n",
      "[[58.1 14.6 15.6 16.7]\n",
      " [16.5 59.2 13.4 15.9]\n",
      " [17.  16.9 55.8 15.3]\n",
      " [13.7 17.9 15.6 57.8]]\n",
      "\tDT\n",
      "Acurácia média (desvio): 0.419524 +- (0.040009)\n",
      "F1-score média (desvio): 0.418916 +- (0.040350)\n",
      "Matriz de Confusão:  \n",
      "[[45.  18.  20.9 21.1]\n",
      " [19.9 45.7 20.  19.4]\n",
      " [20.9 19.7 43.  21.4]\n",
      " [18.3 21.7 22.5 42.5]]\n",
      "\tMLP\n",
      "Acurácia média (desvio): 0.440952 +- (0.041456)\n",
      "F1-score média (desvio): 0.439618 +- (0.041959)\n",
      "Matriz de Confusão:  \n",
      "[[46.1 22.4 19.8 16.7]\n",
      " [16.4 53.4 17.6 17.6]\n",
      " [18.  26.7 41.5 18.8]\n",
      " [18.3 26.3 16.2 44.2]]\n",
      "\tSVM\n",
      "Acurácia média (desvio): 0.428571 +- (0.057921)\n",
      "F1-score média (desvio): 0.428338 +- (0.057691)\n",
      "Matriz de Confusão:  \n",
      "[[45.9 21.1 18.7 19.3]\n",
      " [16.7 44.9 18.1 25.3]\n",
      " [21.2 24.5 41.2 18.1]\n",
      " [17.9 22.8 16.3 48. ]]\n",
      "\tMLR\n",
      "Acurácia média (desvio): 0.291190 +- (0.022589)\n",
      "F1-score média (desvio): 0.280137 +- (0.021750)\n",
      "Matriz de Confusão:  \n",
      "[[17.6 42.4 20.1 24.9]\n",
      " [14.2 50.6 15.5 24.7]\n",
      " [15.3 40.1 24.3 25.3]\n",
      " [16.5 38.4 20.3 29.8]]\n",
      "\tRF\n",
      "Acurácia média (desvio): 0.531905 +- (0.051576)\n",
      "F1-score média (desvio): 0.531249 +- (0.051758)\n",
      "Matriz de Confusão:  \n",
      "[[57.5 15.8 16.8 14.9]\n",
      " [17.1 52.5 16.  19.4]\n",
      " [17.3 16.8 56.  14.9]\n",
      " [15.9 15.4 16.3 57.4]]\n",
      "\tXGB\n",
      "Acurácia média (desvio): 0.396190 +- (0.026517)\n",
      "F1-score média (desvio): 0.395231 +- (0.026329)\n",
      "Matriz de Confusão:  \n",
      "[[41.4 23.2 20.7 19.7]\n",
      " [17.6 42.  19.8 25.6]\n",
      " [22.2 25.7 36.3 20.8]\n",
      " [17.1 22.5 18.7 46.7]]\n",
      "\tGB\n",
      "Acurácia média (desvio): 0.295476 +- (0.027714)\n",
      "F1-score média (desvio): 0.281575 +- (0.029782)\n",
      "Matriz de Confusão:  \n",
      "[[22.7 34.5 20.6 27.2]\n",
      " [19.3 44.6 16.1 25. ]\n",
      " [20.8 35.1 22.4 26.7]\n",
      " [16.7 34.6 19.3 34.4]]\n",
      "\tAB\n",
      "Acurácia média (desvio): 0.305238 +- (0.016316)\n",
      "F1-score média (desvio): 0.303674 +- (0.017225)\n",
      "Matriz de Confusão:  \n",
      "[[29.2 26.  26.9 22.9]\n",
      " [19.9 37.8 22.  25.3]\n",
      " [24.1 29.3 27.2 24.4]\n",
      " [22.7 28.3 20.  34. ]]\n",
      "\n",
      "------- BEST PARAMETERS -------\n",
      "KNN: {'weights': 'uniform', 'n_neighbors': 1, 'metric': 'chebyshev'}\n",
      "DT: {'max_depth': 27, 'criterion': 'gini'}\n",
      "MLP: {'solver': 'sgd', 'learning_rate_init': 0.1, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (100, 25, 10), 'activation': 'tanh'}\n",
      "SVM: {'kernel': 'rbf', 'gamma': 1, 'C': 1}\n",
      "MLR: {'solver': 'newton-cg', 'penalty': 'none'}\n",
      "RF: {'n_estimators': 411, 'max_features': 'log2', 'max_depth': 240}\n",
      "XGB: dic:{'subsample': 0.8, 'objective': 'multi:softmax', 'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "GB: dic:{'n_estimators': 2000, 'learning_rate': 0.1}\n",
      "AB: dic:{'subsample': 1.0, 'n_estimators': 10, 'min_samples_split': 0.24545454545454548, 'min_samples_leaf': 0.17272727272727273, 'max_features': 'sqrt', 'max_depth': 8, 'loss': 'deviance', 'learning_rate': 0.05, 'criterion': 'mae'}\n",
      "--------------------------------------------------------------------------\n",
      "Wall time: 17min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#ignorando warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "params_dict = {}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=199)\n",
    "params_dict = evaluate_model_with_kfold(skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1388b0d6",
   "metadata": {},
   "source": [
    "## Teste\n",
    "\n",
    "Aqui os modelos são execultados no dataset de teste com seus melhores parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "443a0783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test_results(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    #medindo e armazenando acurácia e f1-score no dicionário\n",
    "    \n",
    "    #accuracy = model.score(X_test, y_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    #AUC = roc_auc_score(y_test, model.predict_proba(X_test), average='weighted', multi_class='ovo')\n",
    "    CM = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: %.6f\" %(accuracy))\n",
    "    print(f\"f1: %.6f\" %(f1))\n",
    "    #print(f\"AUC: %.6f\" %(AUC))\n",
    "    print(f\"CM: \\n{CM} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7671774",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "68cac40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['knn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bfdae165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.978889\n",
      "f1: 0.978899\n",
      "CM: \n",
      "[[439   0   3   8]\n",
      " [  3 438   4   5]\n",
      " [  3   3 441   3]\n",
      " [  1   4   1 444]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = knn(**best_param_dict)\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb693314",
   "metadata": {},
   "source": [
    "**PerC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7115f964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.576667\n",
      "f1: 0.577598\n",
      "CM: \n",
      "[[262  55  85  48]\n",
      " [ 71 238  91  50]\n",
      " [ 86  46 279  39]\n",
      " [ 67  41  83 259]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = PerC()\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb04052",
   "metadata": {},
   "source": [
    "**DT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "14fb64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "67969391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.687778\n",
      "f1: 0.687718\n",
      "CM: \n",
      "[[313  55  47  35]\n",
      " [ 51 301  58  40]\n",
      " [ 48  51 298  53]\n",
      " [ 39  38  47 326]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(**best_param_dict, random_state=199)\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd43bdec",
   "metadata": {},
   "source": [
    "**MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "92a3fef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['mlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3583e806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.908333\n",
      "f1: 0.908346\n",
      "CM: \n",
      "[[414  12   9  15]\n",
      " [ 14 414   9  13]\n",
      " [ 12  14 404  20]\n",
      " [ 18  17  12 403]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(\n",
    "            **best_param_dict, \n",
    "            max_iter=2000, \n",
    "            tol=0.000001,\n",
    "            random_state=199\n",
    "        )\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06c4997",
   "metadata": {},
   "source": [
    "**GNB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aedcc720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.373333\n",
      "f1: 0.373617\n",
      "CM: \n",
      "[[167 116  88  79]\n",
      " [ 89 178  96  87]\n",
      " [118 108 153  71]\n",
      " [104 107  65 174]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2f7971",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "04099c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "adf716f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.925000\n",
      "f1: 0.927691\n",
      "CM: \n",
      "[[450   0   0   0]\n",
      " [ 64 386   0   0]\n",
      " [ 42   0 408   0]\n",
      " [ 29   0   0 421]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(**best_param_dict, probability=True, random_state=199)\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7989607",
   "metadata": {},
   "source": [
    "**MLR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "02a9de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['mlr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "296973e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.360000\n",
      "f1: 0.357781\n",
      "CM: \n",
      "[[133 122  94 101]\n",
      " [ 69 184 104  93]\n",
      " [ 89 120 137 104]\n",
      " [ 79 116  61 194]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(**best_param_dict, multi_class='multinomial', random_state=199)\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284fb9d7",
   "metadata": {},
   "source": [
    "**RF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e1655da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['rf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0b646179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.952222\n",
      "f1: 0.952269\n",
      "CM: \n",
      "[[430   3   6  11]\n",
      " [  5 423   7  15]\n",
      " [  2  14 429   5]\n",
      " [  4   7   7 432]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(**best_param_dict, random_state=199)\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749f598f",
   "metadata": {},
   "source": [
    "**XGB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e8720d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['xgb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "34a7fe41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:17:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.901667\n",
      "f1: 0.901667\n",
      "CM: \n",
      "[[410  17  16   7]\n",
      " [ 12 404  17  17]\n",
      " [ 11  16 408  15]\n",
      " [ 19  16  14 401]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(**best_param_dict, random_state=199)\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9fb94b",
   "metadata": {},
   "source": [
    "**Gradient Boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "53a1c153",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['gb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f877b8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.324444\n",
      "f1: 0.311514\n",
      "CM: \n",
      "[[172  84 163  31]\n",
      " [116 128 167  39]\n",
      " [135  60 217  38]\n",
      " [111 112 160  67]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(**best_param_dict, random_state=199)\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a984c",
   "metadata": {},
   "source": [
    "**Ada Boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cacdad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['ab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "23060ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.380556\n",
      "f1: 0.379958\n",
      "CM: \n",
      "[[152 106 102  90]\n",
      " [ 77 185  90  98]\n",
      " [107  83 159 101]\n",
      " [ 93  88  80 189]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(**best_param_dict, random_state=199)\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34cb21e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
